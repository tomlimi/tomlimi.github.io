---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi, I am Tomasz Limisiewicz (yes, with four i’s).
I am currently exploring large language models as a Postdoctoral Researcher at the University of Washington and Meta in Seattle. I PhDid at Charles University.

How do language models acquire unmatched performance throughout diverse tasks? And transfer capabilities across languages and modalities? 
These questions are core to my research. In the exploration, I follow guiding principles:

**I. Focus on Language(s) and Data.**

Studying artifacts of corpora and phenomena characteristic to specific languages and modalities is crucial to understanding the function of language models.
I analyze how models represent concepts and how they enable (or prevent from) tackling high-level challenges.

**II. Divide and Explain.**

 I dissect the black-box models and analyze specific components: attention mechanisms, latent representation, and tokenization.
 This approach allows for identifying the role of specific architecture choices in the learning process. 

**III. Targeted Improvements for Robustness.**

Mechanistic interpretations inform targeted changes and show improvements in aspects that cannot be addressed solely through increasing data volume or model size.
The examples are boosting the representation of low-resource languages and countering biases stemming from data.

Please refer to my [selected publication list](https://tomlimi.github.io/publications/) and [Google Scholar profile](https://scholar.google.com/citations?user=RqxyTsgAAAAJ) for an exhaustive compilation of my scholarly contributions.
 Beyond research: I’m a keen hiker (as depicted in my profile picture from [Veľký Rozsutec](https://en.mapy.cz/s/povofolono)) and a film enthusiast.
